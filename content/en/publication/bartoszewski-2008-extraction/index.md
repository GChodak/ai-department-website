---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Extraction of emotional content from music data
subtitle: ''
summary: ''
authors:
- Marcin Bartoszewski
- Halina Kwasnicka
- Urszula Markowska-Kaczmar
- Pawel B Myszkowski
tags: []
categories: []
date: -01-01
lastmod: 2021-12-15T15:35:03+01:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-12-15T14:35:03.302191Z'
publication_types:
- '1'
abstract: This paper presents the system for automatic emotion detection from music
  data stored in MIDI format files. First, the piece of music is divided into independent
  segments that potentially represent different emotional states. For this task the
  method of segmentation is used. The most important part is a features extraction
  from the music data. On this basis similar emotional parts are grouped by clustering
  algorithm. Music domain knowledge is used to extract features which are then grouped
  hierarchically by agglomerative clustering
publication: '*2008 7th Computer Information Systems and Industrial Management Applications*'
---
