---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Testing word embeddings for Polish
subtitle: ''
summary: ''
authors:
- Agnieszka Mykowiecka
- Ma≈Çgorzata Marciniak
- Piotr Rychlik
tags: []
categories: []
date: -01-01
lastmod: 2021-12-15T15:38:01+01:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-12-15T14:38:00.981922Z'
publication_types:
- '2'
abstract: Distributional Semantics postulates the representation of word meaning in
  the form of numeric vectors which represent words which occur in context in large
  text data. This paper addresses the problem of constructing such models for the
  Polish language. The paper
publication: '*Cognitive Studies*'
---
